{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tarefa9_IdentificacaoPoliticos.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ik8hBBUIrUCa",
        "m42sFerfJND1",
        "hnavM10uJDPQ"
      ],
      "authorship_tag": "ABX9TyMflRxb4bVD4bnV0PLTD7NW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsansao/dlvc/blob/main/Tarefa9_IdentificacaoPoliticos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChPfykV8okAt"
      },
      "source": [
        "# Tarefa 9 - Identificação facial \n",
        "\n",
        "Uma agremiação brasileira resolveu usar um método de identificação facial para autenticar o cadastro de seus filiados. Infelizmente, a solução foi pouco testada e foi um gargalo no processamento dos cadastros. \n",
        "\n",
        "Nessa tarefa, vamos testar os métodos de reconhecimento facial com políticos filiados à referida agremiação. \n",
        "\n",
        "Para completar a tarefa, vamos também testar a rede treinada com fotos dos mesmos políticos com máscaras faciais e avaliar acurácia nas predições com as redes originalmente treinadas. \n",
        "\n",
        "O dataset foi disponibilizado no github com os conjuntos de treinamento e validação separados. Um segundo conjunto de validação, com máscaras também está disponível no repositório. \n",
        "\n",
        "Abaixo, a seqüência para fazer download do dataset e a extração das faces. \n",
        "\n",
        "Você deverá: \n",
        "\n",
        "1. Escolher um método para implementar a identificação (embedding+SVM ou transfer learning com fine tuning, conforme as lições anteriores) \n",
        "\n",
        "2. Treinar a rede, avaliar acurácia de treinamento e validação\n",
        "\n",
        "3. Avaliar a acurácia para o conjunto das imagens com máscara facial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ik8hBBUIrUCa"
      },
      "source": [
        "## Alguns ajustes iniciais"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vKizuGIeig7"
      },
      "source": [
        "!pip install mtcnn\n",
        "!pip install git+https://github.com/jsansao/keras-vggface.git\n",
        "!pip install keras_applications\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evKOfp4UtJ7m"
      },
      "source": [
        "!wget https://github.com/jsansao/TucanoDataset/archive/refs/heads/main.zip\n",
        "!unzip main.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m42sFerfJND1"
      },
      "source": [
        "## Funções para extração das faces e geração do dataset com faces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNsoM-YNeIuP"
      },
      "source": [
        "# face detection \n",
        "from os import listdir\n",
        "from os.path import isdir\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot\n",
        "from numpy import savez_compressed\n",
        "from numpy import asarray\n",
        "import mtcnn\n",
        "\n",
        "# extract a single face from a given photograph\n",
        "def extract_face(filename, required_size=(224, 224)):\n",
        "\t# load image from file\n",
        "\timage = Image.open(filename)\n",
        "\t# convert to RGB, if needed\n",
        "\timage = image.convert('RGB')\n",
        "\t# convert to array\n",
        "\tpixels = asarray(image)\n",
        "\t# create the detector, using default weights\n",
        "\tdetector = mtcnn.MTCNN()\n",
        "\t# detect faces in the image\n",
        "\tresults = detector.detect_faces(pixels)\n",
        "\t# extract the bounding box from the first face\n",
        "\tx1, y1, width, height = results[0]['box']\n",
        "\t# bug fix\n",
        "\tx1, y1 = abs(x1), abs(y1)\n",
        "\tx2, y2 = x1 + width, y1 + height\n",
        "\t# extract the face\n",
        "\tface = pixels[y1:y2, x1:x2]\n",
        "\t# resize pixels to the model size\n",
        "\timage = Image.fromarray(face)\n",
        "\timage = image.resize(required_size)\n",
        "\tface_array = asarray(image)\n",
        "\treturn face_array\n",
        "\n",
        "# load images and extract faces for all images in a directory\n",
        "def load_faces(directory):\n",
        "\tfaces = list()\n",
        "\t# enumerate files\n",
        "\tfor filename in listdir(directory):\n",
        "\t\t# path\n",
        "\t\tpath = directory + filename\n",
        "\t\t# get face\n",
        "\t\tface = extract_face(path, (224,224))\n",
        "\t\t# store\n",
        "\t\tfaces.append(face)\n",
        "\treturn faces\n",
        "\n",
        "# load a dataset that contains one subdir for each class that in turn contains images\n",
        "def load_dataset(directory):\n",
        "\tX, y = list(), list()\n",
        "\t# enumerate folders, on per class\n",
        "\tfor subdir in listdir(directory):\n",
        "\t\t# path\n",
        "\t\tpath = directory + subdir + '/'\n",
        "\t\t# skip any files that might be in the dir\n",
        "\t\tif not isdir(path):\n",
        "\t\t\tcontinue\n",
        "\t\t# load all faces in the subdirectory\n",
        "\t\tfaces = load_faces(path)\n",
        "\t\t# create labels\n",
        "\t\tlabels = [subdir for _ in range(len(faces))]\n",
        "\t\t# summarize progress\n",
        "\t\tprint('>loaded %d examples for class: %s' % (len(faces), subdir))\n",
        "\t\t# store\n",
        "\t\tX.extend(faces)\n",
        "\t\ty.extend(labels)\n",
        "\treturn asarray(X), asarray(y)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnavM10uJDPQ"
      },
      "source": [
        "## Geração dos arquivos com as faces e rótulos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYpCWAmhePGI"
      },
      "source": [
        "# load train dataset\n",
        "trainX, trainy = load_dataset('/content/TucanoDataset-main/train/')\n",
        "print(trainX.shape, trainy.shape)\n",
        "# load test dataset\n",
        "testX, testy = load_dataset('/content/TucanoDataset-main/val/')\n",
        "# load mask dataset\n",
        "valX, valy = load_dataset('/content/TucanoDataset-main/masc_val/')\n",
        "\n",
        "# save arrays to one file in compressed format\n",
        "savez_compressed('tucano-faces-dataset.npz', trainX, trainy, testX, testy, valX, valy)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}